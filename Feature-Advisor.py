import streamlit as st

from langchain_community.document_loaders import UnstructuredMarkdownLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain import ConversationChain
from langchain.llms import OpenAI
from langchain.memory import ConversationBufferMemory
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
import tiktoken

cate = [
  'TV',
'ê°€ë°©ì¡í™”',
'ê²°í˜¼',
'ê²½ë ¥ê°œë°œ',
'ê³ ê°€ìƒí’ˆ',
'ê³ í™”ì§ˆì˜ìƒ',
'ê³µê¸°ì§ˆ',
'êµ­ë‚´ì—¬í–‰',
'ë‚šì‹œ',
'ë‚¨ì„±íŒ¨ì…˜',
'ë†êµ¬',
'ë‹¤ì´ì–´íŠ¸',
'ë‹¬ë¦¬ê¸°',
'ë…ì„œ',
'ë“±ì‚°',
'ë Œíƒˆ',
'ë°˜ë ¤ë™ë¬¼',
'ë³´ì„_ëª…í’ˆ',
'ë³´í—˜',
'ì‚¬ì§„_ì¹´ë©”ë¼',
'ìˆ™ë°•ì—…ì²´',
'ìŠ¤í¬ì¸ ìš´ë™ìš©í’ˆ',
'ì‹ ë°œ',
'ì•„ë™íŒ¨ì…˜',
'ì–´í•™ê³µë¶€',
'ì—¬ì„±íŒ¨ì…˜',
'ì˜¨ë¼ì¸ìƒí’ˆê¶Œ',
'ìš”ê°€',
'ìš”ë¦¬',
'ìœ ì•„êµìœ¡',
'ì˜ë£Œ_ì œì•½',
'ì¸í…Œë¦¬ì–´',
'ìì „ê±°',
'ì£¼ì‹íˆ¬ì',
'ì¤‘ê³ ë“±êµìœ¡',
'ì§€ë„ë„¤ë¹„ê²Œì´ì…˜',
'ì´ˆë“±êµìœ¡',
'ì´ˆë“±í•™êµì €í•™ë…„',
'ì¶•êµ¬',
'ì¶œì‚°',
'íˆ¬ìì •ë³´',
'í•„ë¼í…ŒìŠ¤',
'í•´ì™¸ì—¬í–‰',
'í–¥ìˆ˜í™”ì¥í’ˆ',
'í—¬ìŠ¤',
'í™ˆì¼€ì–´ì„œë¹„ìŠ¤',
'ë‹¨ë§ê¸°íŒŒì†',
'ì•ˆì „_ë°©ì—­',
'ì˜í™”',
'ë©¤ë²„ì‹­í¬ì¸íŠ¸',
'í¸ì˜ì ',
'ë³µê¶Œ',
'ì´ì‚¬',
'ìŒì•…ìŠ¤íŠ¸ë¦¬ë°',
'ì•„ì´ëŒ',
'ë ŒíŠ¸',
'íŒŸìºìŠ¤íŠ¸_ë¼ë””ì˜¤',
'VR',
'ì„±ì¸ì½˜í…ì¸ ',
'ê³¼ì •ì™¸êµìœ¡',
'í”„ë¡œì•¼êµ¬',
'ë®¤ë¨¸',
'ë°˜ë ¤ë™ë¬¼ê´€ì‹¬',
'ë°˜ë ¤ë™ë¬¼ë³´ìœ ',
'êµ­ì±…í•™ìƒ(ìœ í•™ìƒ)',
'ëŒ€í•™ìƒ',
'ê°€ì •ì™¸êµìœ¡',
'ë¶€ëª¨ì„œë¹„ìŠ¤',
'ì˜ë£Œ_ì œì•½',
'ìœ ê¸°ë†ì œí’ˆ',
'êµ¬ë§¤ë ¥',
'ì€í–‰',
'ì˜ì‚¬ê²°ì •ì',
'ì¹´ë“œ',
'ì €ì‹ ìš©ì',
'í•€í…Œí¬',
'ê°„í¸ê²°ì œ',
'ì„¸ê¸ˆ',
'ê°€ìƒí™”í',
'ì „ê¸°ìš”ê¸ˆ',
'íŒ¨ìŠ¤íŠ¸íŒ¨ì…˜ë¸Œëœë“œ',
'ëª…í’ˆì˜ë¥˜',
'íŒ¨ìŠ¤íŠ¸í‘¸ë“œ',
'ë°°ë‹¬ìŒì‹',
'ì´ì‚¬ì„œë¹„ìŠ¤',
'ë¶€ë™ì‚°ì¤‘ê°œ',
'ì•ˆì „_ë°©ë²”',
'í™ˆì¼€ì–´ì„œë¹„ìŠ¤',
'ë™ì˜ìƒìŠ¤íŠ¸ë¦¬ë°',
'ìœ íŠœë¸Œ',
'ì €ê°€ì„ í˜¸',
'E-BOOK',
'ARì½˜í…ì¸ ,'
'ëŒ€í˜•ë§ˆíŠ¸',
'êµ¬ë§¤ì „íƒìƒ‰',
'ì˜¤í”ˆë§ˆì¼“',
'í™ˆì‡¼í•‘',
'í•´ì™¸ì§ì ‘êµ¬ë§¤',
'ë°±í™”ì _ë©´ì„¸ì ',
'ê°€ê²©ë¹„êµ',
'ì£¼ì°¨ì„œë¹„ìŠ¤',
'ëŒ€ì¤‘êµí†µ',
'ëª¨ë¹Œë¦¬í‹°ê³µìœ ì„œë¹„ìŠ¤',
'ë¸”ë¡œê·¸',
'ì˜¨ë¼ì¸ì¹´í˜',
'ì¸ìŠ¤íƒ€ê·¸ë¨',
'SNS',
'í˜ì´ìŠ¤ë¶',
'ì˜¨ë¼ì¸ë‰´ìŠ¤',
'ë‚ ì”¨',
'ê³ ê°ì„¼í„°_ì„œë¹„ìŠ¤ì„¼í„°',
'ëª¨ë°”ì¼ìƒí’ˆ',
'í™ˆìƒí’ˆ',
'MVNO',
'ì‚¼ì„±ëª¨ë°”ì¼',
'ì• í”Œëª¨ë°”ì¼',
'5G',
'ì†ë„ì¸¡ì •',
'ìºì‹œë°±',
'ìœ í¥_ë„ë°•',
'ê³µê³µê¸°ê´€'
]

openai_api_key = st.sidebar.text_input('OpenAI API Key', type='password')

# load inputs

path = './rag_input/category'
loader = DirectoryLoader(path=path)
data = loader.load()


# split documents

tokenizer = tiktoken.get_encoding("cl100k_base")

def tiktoken_len(text):
    tokens = tokenizer.encode(text)
    return len(tokens)

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500, chunk_overlap=0, length_function = tiktoken_len
)
texts = text_splitter.split_documents(data)


# Text Embedding

embeddings_model = OpenAIEmbeddings(openai_api_key=openai_api_key)
# embeddings = embeddings_model.embed_documents([doc.page_content for doc in texts])


# Load into Vector Database
# db = FAISS.from_documents(texts, embeddings_model)
# db.save_local("./db/faiss_index_1")

# Load vector Database
db = FAISS.load_local("./db/faiss_index_1", embeddings_model, allow_dangerous_deserialization=True)

# Retriever
openai = ChatOpenAI(model_name="gpt-4o-2024-05-13",
                    streaming=True, 
                    # callbacks=[StreamingStdOutCallbackHandler()],
                    openai_api_key=openai_api_key,
                    temperature = 0)


qa = RetrievalQA.from_chain_type(llm = openai,
                                 chain_type = "stuff",
                                 retriever = db.as_retriever(
                                    search_type="mmr",
                                    search_kwargs={'k':3, 'fetch_k': 10}),
                                 return_source_documents = True)


st.title('ğŸ¦œğŸ”— Feature Advisor')

query_template = '''
ë„ˆëŠ” ë§ˆì¼€íŒ… ê¸°íšìì•¼.
ì•„ë˜ ì¡°ê±´ì„ ë°˜ì˜í•´ì„œ ì£¼ìš” ì†Œêµ¬ ê³ ê°ì„ ì°¾ê¸° ìœ„í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì²œí•˜ëŠ” ê²ƒì´ ëª©í‘œì•¼

A.ìƒí’ˆì˜ íŠ¹ì„±ì€ ì•„ë˜ì™€ ê°™ì•„

{description}

B. í•´ë‹¹ íšŒì›êµ°ì— ëŒ€í•œ ì „ë°˜ì ì¸ ì„¤ëª…ì„ í•´ì¤˜
 - ì–´ë–¤ ë°ëª¨ê·¸ë˜í”½ì„ ê°–ê³  ìˆëŠ”ì§€, ì£¼ëœ ì‹¬ë¦¬ì  ë™ì¸ì€ ë¬´ì—‡ì¸ì§€, ì–´ë–¤ ê²ƒì„ ì†Œë¹„í•˜ëŠ”ë° ê´€ì‹¬ì´ ë§ì€ì§€ ì•Œë ¤ì¤˜ 
 - ì´ë“¤ì€ ì£¼ë¡œ ì–´ë–¤ ìƒê°ì„ í•˜ê³  ìˆìœ¼ë©°, ì–´ë–¤ ê°€ì¹˜ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ê³ , ê¶ê·¹ì ìœ¼ë¡œ ë¬´ì—‡ì„ ì›í•˜ëŠ”ì§€ì— ëŒ€í•´ ì•Œë ¤ì¤˜
 - 1.ë°ëª¨, 2.ì£¼ìš” ì‹¬ë¦¬ì  ë™ì¸, 3.ì£¼ìš” ê°€ì¹˜, 4. ì£¼ìš” ê´€ì‹¬ì‚¬ì˜ í•­ëª©ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì‘ì„±í•´ì¤˜

C.ì´ì— ì–´ë–¤ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¸ì¡°í•˜ì—¬ ê³ ê°ì„ ì°¾ì•„ì•¼ í•˜ëŠ”ì§€, ì™œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì²œí•˜ëŠ”ì§€ ì•Œë ¤ì¤˜
 - ì¹´í…Œê³ ë¦¬ëŠ” {cate} ì•ˆì˜ ì¹´í…Œê³ ë¦¬ ì¤‘ì—ì„œ ì¶”ì²œí•´ì¤˜
 - ë¨¼ì € ì œê³µëœ ë¬¸ì„œë§Œ ê¸°ë°˜ìœ¼ë¡œ í•´ì„œ ì¹´í…Œê³ ë¦¬ 5ê°œ ì¶”ì²œ, ê·¸ë¦¬ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•´ì¤˜. í•­ëª©ì˜ ì œëª©ì€ 'ì£¼ìš” ì¹´í…Œê³ ë¦¬ ì¶”ì²œ' ìœ¼ë¡œ í•´ì¤˜.
 - ê·¸ë¦¬ê³  ë‚˜ì„œ ì œê³µëœ ë¬¸ì„œì™€ ë„¤ ìƒê°ì„ ëª¨ë‘ í¬í•¨í•´ì„œ ì¹´í…Œê³ ë¦¬ 5ê°œë¥¼ ì¶”ì²œ, ê·¸ë¦¬ê³  ì´ìœ ë¥¼ ì„¤ëª…í•´ì¤˜. 'ì£¼ìš” ì¹´í…Œê³ ë¦¬ ì¶”ì²œ'ì—ì„œ ì¶”ì²œí•œ í•­ëª©ì€ ë˜ ì¶”ì²œí•˜ì§€ ì•Šì•„ë„ ê´œì°®ì•„. í•­ëª©ì˜ ì œëª©ì€ ë³„ë„ë¡œ ë§Œë“¤ì§€ ë§ê³ , 'ì£¼ìš” ì¹´í…Œê³ ë¦¬ ì¶”ì²œ'ì˜ í•˜ìœ„ í•­ëª©ìœ¼ë¡œ ë„£ì–´ì¤˜
 - ì¶”ì²œ ì¹´í…Œê³ ë¦¬ëŠ” ë³„ë„ì˜ í•˜ìœ„í•­ëª© ì—†ì´ 1~10ìœ¼ë¡œ ì¶”ê°€í•´ì¤˜
 

ëª¨ë“  ë‹µë³€ì€ ìì„¸íˆ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜
A-B-Cì˜ ìˆœì„œëŒ€ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ì¤˜
'''

def generate_response(input_text):
    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
    query = query_template.format(description=input_text, cate=cate)

    answer = qa(query)
    st.markdown(answer['result'])

with st.form('my_form'):
    text = st.text_area('Enter text:', 'íƒ€ê²ŸíŒ…í•˜ê³ ì í•˜ëŠ” ìƒí’ˆì˜ íŠ¹ì„±ì„ ì…ë ¥ (íŠ¹ì„±, ì†Œêµ¬ì , íƒ€ê²Ÿê³ ê° ë“±)')
    submitted = st.form_submit_button('Submit')
    if not openai_api_key.startswith('sk-'):
        st.warning('Please enter your OpenAI API key!', icon='âš ')
    if submitted and openai_api_key.startswith('sk-'):
        generate_response(text)